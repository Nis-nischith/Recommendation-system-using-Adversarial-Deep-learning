{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyxpIFFa8r0E",
        "outputId": "69715344-7086-4d73-c212-34f2dc8175fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import warnings\n",
        "import copy\n",
        "import random\n",
        "from keras import layers, models\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "!pip install torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device: use GPU if available, otherwise fallback to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define base path to save trained models and other outputs\n",
        "save_base_path = \"/path/to/save\""
      ],
      "metadata": {
        "id": "vkrhmkaQ82lJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "\n",
        "# Download the dataset\n",
        "response = requests.get(url)\n",
        "zip_file = zipfile.ZipFile(BytesIO(response.content))\n",
        "\n",
        "# Extract the ratings and movies CSV files\n",
        "ratings = pd.read_csv(zip_file.open('ml-latest-small/ratings.csv'))\n",
        "movies = pd.read_csv(zip_file.open('ml-latest-small/movies.csv'))\n",
        "\n",
        "# Preview the datasets\n",
        "print(ratings.head())\n",
        "print(movies.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqOlp4AX-heD",
        "outputId": "fdee755f-5c3f-4444-adbc-616780c7ba2e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating  timestamp\n",
            "0       1        1     4.0  964982703\n",
            "1       1        3     4.0  964981247\n",
            "2       1        6     4.0  964982224\n",
            "3       1       47     5.0  964983815\n",
            "4       1       50     5.0  964982931\n",
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1                   Adventure|Children|Fantasy  \n",
            "2                               Comedy|Romance  \n",
            "3                         Comedy|Drama|Romance  \n",
            "4                                       Comedy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique users and items from the ratings dataset\n",
        "users = ratings['userId'].unique()\n",
        "items = ratings['movieId'].unique()\n",
        "\n",
        "# Create mappings from user/item IDs to indices (used for embedding)\n",
        "user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
        "item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
        "\n",
        "# Convert user and item IDs in ratings to indices\n",
        "ratings['user_idx'] = ratings['userId'].apply(lambda x: user_to_idx[x])\n",
        "ratings['item_idx'] = ratings['movieId'].apply(lambda x: item_to_idx[x])"
      ],
      "metadata": {
        "id": "Khb8ogtB-j_i"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J8N2zM3-osx",
        "outputId": "82fd0e4c-d2f8-4476-c545-4c1bf2308a9d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        userId  movieId  rating   timestamp  user_idx  item_idx\n",
            "0            1        1     4.0   964982703         0         0\n",
            "1            1        3     4.0   964981247         0         1\n",
            "2            1        6     4.0   964982224         0         2\n",
            "3            1       47     5.0   964983815         0         3\n",
            "4            1       50     5.0   964982931         0         4\n",
            "...        ...      ...     ...         ...       ...       ...\n",
            "100831     610   166534     4.0  1493848402       609      3120\n",
            "100832     610   168248     5.0  1493850091       609      2035\n",
            "100833     610   168250     5.0  1494273047       609      3121\n",
            "100834     610   168252     5.0  1493846352       609      1392\n",
            "100835     610   170875     3.0  1493846415       609      2873\n",
            "\n",
            "[100836 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(users.size)\n",
        "print(items.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz8-jvIx_B0G",
        "outputId": "b6e44ec9-3c81-40da-b5f5-037dd6f5107e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "610\n",
            "9724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_matrix = ratings.pivot(index='user_idx', columns='item_idx', values='rating').fillna(0)"
      ],
      "metadata": {
        "id": "oGfqaoXu-pLI"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_array= np.array(interaction_matrix)\n",
        "print(interaction_array)\n",
        "print('matrix dimensions : ', interaction_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLEMFhUw-rQi",
        "outputId": "3e401cb3-e771-44c3-8431-2287e5cdf50a"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.  4.  4.  ... 0.  0.  0. ]\n",
            " [0.  0.  0.  ... 0.  0.  0. ]\n",
            " [0.  0.  0.  ... 0.  0.  0. ]\n",
            " ...\n",
            " [2.5 2.  0.  ... 0.  0.  0. ]\n",
            " [3.  0.  0.  ... 0.  0.  0. ]\n",
            " [5.  0.  5.  ... 3.  3.5 3.5]]\n",
            "matrix dimensions :  (610, 9724)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UserItemDataset(Dataset):\n",
        "    def __init__(self, ratings):\n",
        "        self.ratings = ratings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.ratings.iloc[idx]\n",
        "        return {\n",
        "            'user_idx': torch.tensor(row['user_idx'], dtype=torch.long),\n",
        "            'item_idx': torch.tensor(row['item_idx'], dtype=torch.long),\n",
        "            'rating': torch.tensor(row['rating'], dtype=torch.float),\n",
        "        }\n",
        "\n",
        "# Create train, validation, and test splits (80% train, 10% validation, 10% test)\n",
        "train_size = int(len(ratings))\n",
        "val_size = int(0 * len(ratings))\n",
        "# test_size = len(ratings) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(ratings, [train_size, val_size])\n",
        "\n",
        "# Create data loaders for batching\n",
        "train_loader = DataLoader(UserItemDataset(ratings.iloc[train_dataset.indices]), batch_size=32, shuffle=True)\n",
        "# val_loader = DataLoader(UserItemDataset(ratings.iloc[val_dataset.indices]), batch_size=32, shuffle= True)\n",
        "# test_loader = DataLoader(UserItemDataset(ratings.iloc[test_dataset.indices]), batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "CTOrY6LzS1eR"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MFModel(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_size):\n",
        "        super(MFModel, self).__init__()\n",
        "        # Create embedding layers for users and items\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
        "\n",
        "    def forward(self, user_ids, item_ids):\n",
        "        # Get user and item embeddings\n",
        "        user_embedding = self.user_embedding(user_ids)\n",
        "        item_embedding = self.item_embedding(item_ids)\n",
        "        # Compute the dot product between user and item embeddings\n",
        "        dot_product = (user_embedding * item_embedding).sum(dim=1)\n",
        "        return dot_product\n",
        "\n",
        "# Initialize the model with number of users, items, and the embedding size\n",
        "num_users = len(users)\n",
        "num_items = len(items)\n",
        "embedding_size = 50  # This is a tunable hyperparameter"
      ],
      "metadata": {
        "id": "NMgM9RCLS-em"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mf_model1 = MFModel(num_users, num_items, embedding_size).to(device)\n",
        "optimizer = optim.Adam(mf_model1.parameters(), lr=0.001)  # Adam optimizer\n",
        "loss_fn = nn.MSELoss()  # Loss function (Mean Squared Error)"
      ],
      "metadata": {
        "id": "pqzhlDhES_M5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mf_model(model, train_loader, optimizer, criterion, num_epochs=10):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            user_ids = batch['user_idx'].to(device)\n",
        "            item_ids = batch['item_idx'].to(device)\n",
        "            ratings = batch['rating'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the gradients\n",
        "            preds = model(user_ids, item_ids)  # Forward pass\n",
        "            loss = criterion(preds, ratings)  # Compute loss\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Gradient descent step\n",
        "            total_loss += loss.item()  # Accumulate loss\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}')"
      ],
      "metadata": {
        "id": "aF4Vor3dTCsI"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mf_model(mf_model1, train_loader, optimizer, loss_fn)"
      ],
      "metadata": {
        "id": "J_nVp17UTF2o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "outputId": "e5dc2038-eccf-439f-fb3e-faa2567b5816"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-82d362da8991>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_mf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf_model1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-85-834695f239d6>\u001b[0m in \u001b[0;36mtrain_mf_model\u001b[0;34m(model, train_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0muser_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mitem_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-4324e6f6e548>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m         return {\n\u001b[1;32m     11\u001b[0m             \u001b[0;34m'user_idx'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0;34m'item_idx'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;34m'rating'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         }\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    user_embeddings = mf_model1.user_embedding.weight.cpu().numpy()\n",
        "    item_embeddings = mf_model1.item_embedding.weight.cpu().numpy()"
      ],
      "metadata": {
        "id": "9TudjFxsTJUq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_graph_data(ratings,num_users,user_embeddings,item_embeddings):\n",
        "    user_item_edges = ratings[['user_idx', 'item_idx']].values.T  # Create edges between user-item pairs\n",
        "\n",
        "    user_item_edges[1] += num_users\n",
        "\n",
        "    # Create edge index (format required by torch_geometric)\n",
        "    edge_index = torch.tensor(user_item_edges, dtype=torch.long)\n",
        "\n",
        "    # Concatenate user and item embeddings to form node features\n",
        "    node_features = torch.cat([torch.tensor(user_embeddings, dtype=torch.float), torch.tensor(item_embeddings, dtype=torch.float)], dim=0)\n",
        "\n",
        "    print(node_features.shape)\n",
        "    print(user_item_edges.shape)\n",
        "    print(user_item_edges)\n",
        "\n",
        "    # Create the PyTorch Geometric data object (x: node features, edge_index: graph edges)\n",
        "    train_graph_data = Data(x=node_features, edge_index=edge_index)\n",
        "    return train_graph_data"
      ],
      "metadata": {
        "id": "E9X8Dn7KTMLq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_graph_data = create_graph_data(ratings,num_users,user_embeddings,item_embeddings)"
      ],
      "metadata": {
        "id": "JZvMir2qTMvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996f5f34-1aab-41e8-c08a-7c743921a168"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10334, 50])\n",
            "(2, 100836)\n",
            "[[   0    0    0 ...  609  609  609]\n",
            " [ 610  611  612 ... 3731 2002 3483]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNModel(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNModel, self).__init__()\n",
        "        # First graph convolutional layer\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        # Second graph convolutional layer\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # Forward pass through the first graph convolutional layer\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)  # Apply ReLU non-linearity\n",
        "        # Forward pass through the second graph convolutional layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dZnlguav_GoE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = GCNModel(in_channels=embedding_size, hidden_channels=64, out_channels=32).to(device)"
      ],
      "metadata": {
        "id": "NzGkvDQg_J7v"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_optimizer = optim.Adam(model1.parameters(), lr=0.01)\n",
        "gcn_loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "j2TwdIWb_LmW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gcn_model(model, train_graph, optimizer, criterion, interaction_matrix,num_epochs=30):\n",
        "    model.train()  # Set model to training mode\n",
        "    user_embed=[]\n",
        "    item_embed=[]\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        output = model(train_graph)  # Forward pass through the GCN\n",
        "\n",
        "\n",
        "        #print('output dimension',output.shape)\n",
        "        # Assuming user_idx and item_idx are indices of user-item pairs\n",
        "        user_indices = ratings['user_idx'].unique()  # Indices for users\n",
        "        item_indices = ratings['item_idx'].unique()  # Indices for items\n",
        "\n",
        "\n",
        "        #print('user indices dimension check',user_indices.shape)\n",
        "        #print('item indices dimension check',item_indices.shape)\n",
        "        # Get embeddings for the relevant user-item pairs\n",
        "        user_embeddings = output[user_indices]  # Shape: (N, embedding_size)\n",
        "        item_embeddings = output[item_indices + num_users]  # Shift by num_users for items\n",
        "\n",
        "        # Compute predicted ratings\n",
        "        predicted_ratings = torch.matmul(user_embeddings, item_embeddings.T) # Dot product\n",
        "\n",
        "        # Get target ratings from interaction matrix\n",
        "        interaction_tensor = torch.tensor(interaction_matrix.values, dtype=torch.float32)\n",
        "        target= interaction_tensor\n",
        "        #target = interaction_tensor[user_indices, item_indices].view(-1)  # Flatten to match\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(predicted_ratings, target)\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Gradient descent step\n",
        "\n",
        "        user_embed= user_embeddings\n",
        "        item_embed= item_embeddings\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "    return user_embed, item_embed"
      ],
      "metadata": {
        "id": "8ntiWG2s_N2e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_embeddings, item_embeddings= train_gcn_model(model1, train_graph_data, gcn_optimizer, gcn_loss_fn, interaction_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ46r33u_OTr",
        "outputId": "ef126a41-0513-4473-fd98-5fc2082ab32d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 74.7393\n",
            "Epoch 2/30, Loss: 5.2746\n",
            "Epoch 3/30, Loss: 4.8273\n",
            "Epoch 4/30, Loss: 9.4986\n",
            "Epoch 5/30, Loss: 10.6388\n",
            "Epoch 6/30, Loss: 8.3612\n",
            "Epoch 7/30, Loss: 5.8143\n",
            "Epoch 8/30, Loss: 3.8968\n",
            "Epoch 9/30, Loss: 2.6151\n",
            "Epoch 10/30, Loss: 1.8156\n",
            "Epoch 11/30, Loss: 1.3357\n",
            "Epoch 12/30, Loss: 1.0451\n",
            "Epoch 13/30, Loss: 0.8618\n",
            "Epoch 14/30, Loss: 0.7418\n",
            "Epoch 15/30, Loss: 0.6582\n",
            "Epoch 16/30, Loss: 0.5974\n",
            "Epoch 17/30, Loss: 0.5513\n",
            "Epoch 18/30, Loss: 0.5150\n",
            "Epoch 19/30, Loss: 0.4859\n",
            "Epoch 20/30, Loss: 0.4620\n",
            "Epoch 21/30, Loss: 0.4421\n",
            "Epoch 22/30, Loss: 0.4251\n",
            "Epoch 23/30, Loss: 0.4102\n",
            "Epoch 24/30, Loss: 0.3970\n",
            "Epoch 25/30, Loss: 0.3852\n",
            "Epoch 26/30, Loss: 0.3745\n",
            "Epoch 27/30, Loss: 0.3647\n",
            "Epoch 28/30, Loss: 0.3558\n",
            "Epoch 29/30, Loss: 0.3476\n",
            "Epoch 30/30, Loss: 0.3402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_embeddings)\n",
        "print(user_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPXwSycf_QhY",
        "outputId": "96d68520-e3bd-40a5-8544-a77d6e58a8da"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2572,  0.0737, -0.0401,  ..., -0.1844, -0.3863,  0.1713],\n",
            "        [ 1.1857,  0.6170, -0.8158,  ..., -1.2879, -0.5507, -0.7424],\n",
            "        [-0.7403, -0.1380, -0.5928,  ..., -0.9412, -0.9063, -0.3348],\n",
            "        ...,\n",
            "        [-0.0207,  0.0797, -0.0270,  ...,  0.0047,  0.0094,  0.0215],\n",
            "        [ 0.9587, -0.1195, -0.7350,  ...,  0.1593,  0.0339,  0.7046],\n",
            "        [-0.0322,  0.0967, -0.0094,  ...,  0.0062,  0.0124,  0.0148]],\n",
            "       grad_fn=<IndexBackward0>)\n",
            "torch.Size([610, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(item_embeddings)\n",
        "print(item_embeddings.shape)\n",
        "old_item_embeddings= item_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc4dNb8S_Scs",
        "outputId": "e0c3a228-7fa5-49d2-f816-53d3ffaf423f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1911,  1.2820, -0.0076,  ...,  0.2630,  0.0987, -0.3907],\n",
            "        [ 0.1513,  0.5433,  0.0576,  ..., -0.1745,  0.1631, -0.2930],\n",
            "        [-0.1279,  0.8484,  0.0539,  ...,  0.4865,  0.1126, -0.7557],\n",
            "        ...,\n",
            "        [-0.0319,  0.2110, -0.0112,  ...,  0.0293,  0.0264,  0.0817],\n",
            "        [ 0.0226,  0.0739, -0.0111,  ...,  0.0253,  0.1290,  0.1384],\n",
            "        [-0.0733,  0.2177, -0.0644,  ...,  0.0327,  0.0119,  0.0159]],\n",
            "       grad_fn=<IndexBackward0>)\n",
            "torch.Size([9724, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_gcn_model(model, user_embeddings, item_embeddings, interaction_matrix):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "\n",
        "        predicted_ratings = torch.matmul(user_embeddings, item_embeddings.T)\n",
        "        interaction_tensor = torch.tensor(interaction_matrix.values, dtype=torch.float32)\n",
        "        target= interaction_tensor\n",
        "\n",
        "        rmse = np.sqrt(mean_squared_error(target, predicted_ratings))  # Compute RMSE\n",
        "        print(f'RMSE: {rmse:.4f}')"
      ],
      "metadata": {
        "id": "c7PDqhGq_T9J"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_new_user_rating(item_embeddings, masked_array, num_users=num_users):\n",
        "    item_embeddings = item_embeddings.detach().numpy()\n",
        "    masked_array = np.array(masked_array, dtype=np.float32)\n",
        "\n",
        "    masked_array = masked_array.reshape(-1, 1)  # Shape: (num_items, 1)\n",
        "    weighted_sum = np.sum(item_embeddings * masked_array, axis=0)\n",
        "    sum_of_weights = np.sum(masked_array)\n",
        "    new_user_embedding = weighted_sum / sum_of_weights\n",
        "    predicted_ratings = np.dot(item_embeddings, new_user_embedding)\n",
        "\n",
        "    return predicted_ratings"
      ],
      "metadata": {
        "id": "zmZEYV0E_nD-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_test(num_users, interaction_array, item_embeddings):\n",
        "    metric=0\n",
        "    for i in range(len(interaction_array) - num_users, len(interaction_array)):\n",
        "        normal_test = interaction_array[i]\n",
        "        non_zero_indices = np.nonzero(normal_test)[0]\n",
        "        num_values_to_keep = len(non_zero_indices) // 2\n",
        "        selected_indices = np.random.choice(non_zero_indices, size=num_values_to_keep, replace=False)\n",
        "        masked_array = np.zeros_like(normal_test)\n",
        "        masked_array[selected_indices] = normal_test[selected_indices]\n",
        "        prediction = predict_new_user_rating(item_embeddings, masked_array)\n",
        "        prediction= np.clip(prediction, 0, 5)\n",
        "        rmse = np.sqrt(np.mean((prediction - normal_test) ** 2))\n",
        "        metric+= rmse\n",
        "    return metric/num_users"
      ],
      "metadata": {
        "id": "Tz2QI3xC_q1O"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RNDmcH2GDMXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_gcn_model(model1, user_embeddings, item_embeddings,  interaction_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XaZWT63_uUQ",
        "outputId": "f8852c27-8f17-4c13-f9a8-089f944cac26"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.5832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RECNORMAL"
      ],
      "metadata": {
        "id": "ycfDDE5LDVt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_test(50, interaction_array, old_item_embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQOH7Kfx_wZS",
        "outputId": "94deee95-6262-4c8c-b2e3-320c0534c3d9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1436645739520044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PHASE 2"
      ],
      "metadata": {
        "id": "JE02PJExGMeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder: Maps interaction matrix to latent space\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, latent_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "NoeQypng-y4a"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator: Generates perturbed interactions\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, output_dim),\n",
        "            nn.Tanh(),  # Output perturbations in range [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)"
      ],
      "metadata": {
        "id": "ioYc8nOh-62k"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_encoder_generator(encoder, generator, interaction_matrix, num_epochs=20, batch_size=61, lr=0.001, lambda_reg=0.1):\n",
        "    e_optimizer = torch.optim.Adam(encoder.parameters(), lr=lr)\n",
        "    g_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i in range(0, len(interaction_matrix), batch_size):\n",
        "            # Get batch of data\n",
        "            real_data = interaction_matrix[i:i + batch_size]\n",
        "            batch_size = real_data.size(0)\n",
        "\n",
        "            # Encode real data to latent space\n",
        "            latent_real = encoder(real_data)\n",
        "\n",
        "            # Generate perturbations\n",
        "            perturbations = generator(latent_real)\n",
        "\n",
        "            # Create perturbed matrix\n",
        "            perturbed_data = real_data + perturbations\n",
        "            perturbed_data = torch.clamp(perturbed_data, 0, 5)  # Clip to valid range [0, 5]\n",
        "\n",
        "            # Loss: Reconstruction + Regularization\n",
        "            recon_loss = mse_loss(perturbed_data, real_data)\n",
        "            reg_loss = lambda_reg * torch.norm(perturbations, p=2)\n",
        "            loss = recon_loss + reg_loss\n",
        "\n",
        "            # Backward and optimization\n",
        "            e_optimizer.zero_grad()\n",
        "            g_optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            e_optimizer.step()\n",
        "            g_optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    return encoder, generator"
      ],
      "metadata": {
        "id": "A3bNivcd-88M"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_matrix= torch.tensor(interaction_array, dtype=torch.float32)\n",
        "print(interaction_matrix)\n",
        "interaction_matrix = interaction_matrix.float()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT1eyFM9BmND",
        "outputId": "1f74f726-9d89-4ad0-8392-ad98e2175445"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.0000, 4.0000, 4.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [2.5000, 2.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [3.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [5.0000, 0.0000, 5.0000,  ..., 3.0000, 3.5000, 3.5000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_items = interaction_matrix.size(1)\n",
        "latent_dim = 8\n",
        "\n",
        "# Initialize encoder and generator\n",
        "encoder = Encoder(input_dim=num_items, latent_dim=latent_dim)\n",
        "generator = Generator(latent_dim=latent_dim, output_dim=num_items)"
      ],
      "metadata": {
        "id": "HHGY8RZOB1rd"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the encoder and generator\n",
        "encoder, generator = train_encoder_generator(\n",
        "    encoder, generator, interaction_matrix, num_epochs=10, batch_size=61, lr=0.01, lambda_reg=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td4X4LWUCDM_",
        "outputId": "37e4a9a4-f044-4199-9946-e8895662f82a"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 29.6222\n",
            "Epoch 2/10, Loss: 8.8403\n",
            "Epoch 3/10, Loss: 4.0263\n",
            "Epoch 4/10, Loss: 2.7743\n",
            "Epoch 5/10, Loss: 1.3858\n",
            "Epoch 6/10, Loss: 0.7618\n",
            "Epoch 7/10, Loss: 0.5064\n",
            "Epoch 8/10, Loss: 0.4296\n",
            "Epoch 9/10, Loss: 0.3393\n",
            "Epoch 10/10, Loss: 0.4449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate perturbed interactions\n",
        "with torch.no_grad():\n",
        "    latent_real = encoder(interaction_matrix)\n",
        "    perturbations = generator(latent_real)\n",
        "    perturbed_matrix = torch.clamp(interaction_matrix + perturbations*10, 0, 5)\n",
        "\n",
        "print(\"Original Interaction Matrix:\")\n",
        "print(interaction_matrix)\n",
        "\n",
        "print(\"Perturbed Interaction Matrix:\")\n",
        "print(perturbed_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75ekP2V1CHSf",
        "outputId": "04ecf634-9eed-4b20-f6f7-345203149aaf"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Interaction Matrix:\n",
            "tensor([[4.0000, 4.0000, 4.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [2.5000, 2.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [3.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [5.0000, 0.0000, 5.0000,  ..., 3.0000, 3.5000, 3.5000]])\n",
            "Perturbed Interaction Matrix:\n",
            "tensor([[4.0027e+00, 4.0025e+00, 3.9960e+00,  ..., 5.5158e-03, 1.5042e-02,\n",
            "         0.0000e+00],\n",
            "        [2.6638e-03, 2.4732e-03, 0.0000e+00,  ..., 5.5158e-03, 1.5042e-02,\n",
            "         0.0000e+00],\n",
            "        [1.3525e-02, 9.0535e-03, 0.0000e+00,  ..., 1.1342e-02, 1.2437e-02,\n",
            "         1.3604e-03],\n",
            "        ...,\n",
            "        [2.5027e+00, 2.0025e+00, 0.0000e+00,  ..., 5.5158e-03, 1.5042e-02,\n",
            "         0.0000e+00],\n",
            "        [3.0027e+00, 2.4732e-03, 0.0000e+00,  ..., 5.5158e-03, 1.5042e-02,\n",
            "         0.0000e+00],\n",
            "        [5.0000e+00, 2.4732e-03, 4.9960e+00,  ..., 3.0055e+00, 3.5150e+00,\n",
            "         3.4997e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_array_manipulated= np.array(perturbed_matrix)"
      ],
      "metadata": {
        "id": "HJ-AExvYBJ2V"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_indices, item_indices = np.nonzero(interaction_array_manipulated)  # Get indices of non-zero elements\n",
        "\n",
        "# Retrieve the corresponding ratings from interaction_array\n",
        "ratings = interaction_array_manipulated[user_indices, item_indices]\n",
        "\n",
        "# Create a DataFrame similar to the original ratings DataFrame\n",
        "reconstructed_ratings = pd.DataFrame({\n",
        "    'user_idx': user_indices,\n",
        "    'item_idx': item_indices,\n",
        "    'rating': ratings\n",
        "})\n",
        "\n",
        "# Print to verify\n",
        "print(reconstructed_ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjjfG48L_zvh",
        "outputId": "f10a57aa-d754-4b8c-b4c7-b146e151a551"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         user_idx  item_idx    rating\n",
            "0               0         0  3.995596\n",
            "1               0         1  3.983047\n",
            "2               0         2  3.991979\n",
            "3               0         3  4.974822\n",
            "4               0         4  5.000000\n",
            "...           ...       ...       ...\n",
            "3052220       609      9719  2.527466\n",
            "3052221       609      9720  4.521444\n",
            "3052222       609      9721  3.014028\n",
            "3052223       609      9722  3.470690\n",
            "3052224       609      9723  3.474229\n",
            "\n",
            "[3052225 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = reconstructed_ratings"
      ],
      "metadata": {
        "id": "eFVgsSTnATJV"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(ratings))\n",
        "val_size = int(0 * len(ratings))\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(ratings, [train_size, val_size])"
      ],
      "metadata": {
        "id": "V5_8pV6PAY1R"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(UserItemDataset(ratings.iloc[train_dataset.indices]), batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "XRIiRjLiAaXr"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users = ratings['user_idx'].unique()\n",
        "items = ratings['item_idx'].unique()\n",
        "\n",
        "# Create mappings from user/item IDs to indices (used for embedding)\n",
        "user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
        "item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
        "\n",
        "# Convert user and item IDs in ratings to indices\n",
        "ratings['user_idx'] = ratings['user_idx'].apply(lambda x: user_to_idx[x])\n",
        "ratings['item_idx'] = ratings['item_idx'].apply(lambda x: item_to_idx[x])"
      ],
      "metadata": {
        "id": "yO_WuXf1AcUQ"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = len(users)\n",
        "num_items = len(items)\n",
        "embedding_size = 50  # This is a tunable hyperparameter"
      ],
      "metadata": {
        "id": "ZRjKdvp1AtzT"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mf_model2 = MFModel(num_users, num_items, embedding_size).to(device)\n",
        "optimizer = optim.Adam(mf_model2.parameters(), lr=0.001)  # Adam optimizer\n",
        "loss_fn = nn.MSELoss()  # Loss function (Mean Squared Error)"
      ],
      "metadata": {
        "id": "htfPyGqfAxI3"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_users, num_items, mf_model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9vhJnuiAy5_",
        "outputId": "10e0dced-8746-4253-ef29-477f36138b99"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "610 9724 MFModel(\n",
            "  (user_embedding): Embedding(610, 50)\n",
            "  (item_embedding): Embedding(9724, 50)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mf_model(mf_model2, train_loader, optimizer, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "-OLk3an4A0kI",
        "outputId": "4f021ca5-a84e-4739-9175-fb64cc0ebb23"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 6.0610\n",
            "Epoch 2/10, Loss: 0.2714\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-9e7cd502461e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_mf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf_model2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-89-834695f239d6>\u001b[0m in \u001b[0;36mtrain_mf_model\u001b[0;34m(model, train_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Gradient descent step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Accumulate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    user_embeddings = mf_model2.user_embedding.weight.cpu().numpy()\n",
        "    item_embeddings = mf_model2.item_embedding.weight.cpu().numpy()"
      ],
      "metadata": {
        "id": "JGSqhbqpA2XN"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_embeddings.shape)\n",
        "print(user_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lH6fihzA4I_",
        "outputId": "90429b1c-2409-43db-f5a9-634a58999740"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(610, 50)\n",
            "[[-0.16655071 -0.14482775 -0.201875   ...  0.16497223  0.3168738\n",
            "   0.12480289]\n",
            " [-0.01345349 -0.15575585 -0.10927371 ...  0.12519373  0.05076575\n",
            "  -0.01967353]\n",
            " [-0.0124421  -0.01666914  0.00300997 ...  0.03072039  0.00310987\n",
            "  -0.00123911]\n",
            " ...\n",
            " [-0.129569    0.19761652 -0.24201405 ...  0.3385542   0.3853156\n",
            "  -0.14142798]\n",
            " [ 0.07561697 -0.15028955 -0.08454427 ...  0.08043491  0.02444841\n",
            "   0.16111022]\n",
            " [-0.49085128  0.34762907 -0.22968818 ...  0.42147285  0.3863847\n",
            "  -0.16555476]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_graph_data = create_graph_data(ratings,num_users,user_embeddings,item_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lawL7jYOA51_",
        "outputId": "a3e06ad2-a5d9-4918-dc42-0239dfe18cb3"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10334, 50])\n",
            "(2, 3052225)\n",
            "[[    0     0     0 ...   609   609   609]\n",
            " [  610   611   612 ...  5639 10332 10333]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = GCNModel(in_channels=embedding_size, hidden_channels=64, out_channels=32).to(device)\n",
        "gcn_optimizer = optim.Adam(model2.parameters(), lr=0.01)\n",
        "gcn_loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "FwdVRZKbA75W"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_matrix_manipulated = ratings.pivot(index='user_idx', columns='item_idx', values='rating').fillna(0)"
      ],
      "metadata": {
        "id": "zqkFi2WlA9or"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_embeddings, item_embeddings= train_gcn_model(model2, train_graph_data, gcn_optimizer, gcn_loss_fn, interaction_matrix_manipulated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEValFyzA_xJ",
        "outputId": "41e77105-26da-440f-e99b-a7615485b74a"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 10.6492\n",
            "Epoch 2/30, Loss: 0.3536\n",
            "Epoch 3/30, Loss: 1.5777\n",
            "Epoch 4/30, Loss: 2.0957\n",
            "Epoch 5/30, Loss: 1.0939\n",
            "Epoch 6/30, Loss: 0.5137\n",
            "Epoch 7/30, Loss: 0.3128\n",
            "Epoch 8/30, Loss: 0.2505\n",
            "Epoch 9/30, Loss: 0.2304\n",
            "Epoch 10/30, Loss: 0.2234\n",
            "Epoch 11/30, Loss: 0.2208\n",
            "Epoch 12/30, Loss: 0.2198\n",
            "Epoch 13/30, Loss: 0.2196\n",
            "Epoch 14/30, Loss: 0.2196\n",
            "Epoch 15/30, Loss: 0.2197\n",
            "Epoch 16/30, Loss: 0.2198\n",
            "Epoch 17/30, Loss: 0.2199\n",
            "Epoch 18/30, Loss: 0.2200\n",
            "Epoch 19/30, Loss: 0.2200\n",
            "Epoch 20/30, Loss: 0.2200\n",
            "Epoch 21/30, Loss: 0.2199\n",
            "Epoch 22/30, Loss: 0.2199\n",
            "Epoch 23/30, Loss: 0.2197\n",
            "Epoch 24/30, Loss: 0.2196\n",
            "Epoch 25/30, Loss: 0.2195\n",
            "Epoch 26/30, Loss: 0.2193\n",
            "Epoch 27/30, Loss: 0.2191\n",
            "Epoch 28/30, Loss: 0.2190\n",
            "Epoch 29/30, Loss: 0.2188\n",
            "Epoch 30/30, Loss: 0.2186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_gcn_model(model2, user_embeddings, item_embeddings,  interaction_matrix_manipulated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6mQ0ndvBBgO",
        "outputId": "779b441e-18b3-40a4-f4a3-e61753f6f619"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.4676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RECSECURE"
      ],
      "metadata": {
        "id": "VTB41AqDDejU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_test(50, interaction_array_manipulated, item_embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9NNBOYDBDUV",
        "outputId": "ed5fc835-95e7-4c6c-b271-0d71e95cbb98"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7436637020111084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RECMANI"
      ],
      "metadata": {
        "id": "5eBTm1ozDiGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_test(50, interaction_array_manipulated, old_item_embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGjdKe0IBFRm",
        "outputId": "8e1c4e47-81e1-4984-80fe-392577800dfb"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.125307434797287\n"
          ]
        }
      ]
    }
  ]
}