{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xyxpIFFa8r0E",
    "outputId": "69715344-7086-4d73-c212-34f2dc8175fe"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import warnings\n",
    "import copy\n",
    "import random\n",
    "from keras import layers, models\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "!pip install torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkrhmkaQ82lJ"
   },
   "outputs": [],
   "source": [
    "# Set device: use GPU if available, otherwise fallback to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define base path to save trained models and other outputs\n",
    "save_base_path = \"/path/to/save\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqOlp4AX-heD",
    "outputId": "fdee755f-5c3f-4444-adbc-616780c7ba2e"
   },
   "outputs": [],
   "source": [
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "\n",
    "# Download the dataset\n",
    "response = requests.get(url)\n",
    "zip_file = zipfile.ZipFile(BytesIO(response.content))\n",
    "\n",
    "# Extract the ratings and movies CSV files\n",
    "ratings = pd.read_csv(zip_file.open('ml-latest-small/ratings.csv'))\n",
    "movies = pd.read_csv(zip_file.open('ml-latest-small/movies.csv'))\n",
    "\n",
    "# Preview the datasets\n",
    "print(ratings.head())\n",
    "print(movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Khb8ogtB-j_i"
   },
   "outputs": [],
   "source": [
    "# Get unique users and items from the ratings dataset\n",
    "users = ratings['userId'].unique()\n",
    "items = ratings['movieId'].unique()\n",
    "\n",
    "# Create mappings from user/item IDs to indices (used for embedding)\n",
    "user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
    "\n",
    "# Convert user and item IDs in ratings to indices\n",
    "ratings['user_idx'] = ratings['userId'].apply(lambda x: user_to_idx[x])\n",
    "ratings['item_idx'] = ratings['movieId'].apply(lambda x: item_to_idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4J8N2zM3-osx",
    "outputId": "82fd0e4c-d2f8-4476-c545-4c1bf2308a9d"
   },
   "outputs": [],
   "source": [
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hz8-jvIx_B0G",
    "outputId": "b6e44ec9-3c81-40da-b5f5-037dd6f5107e"
   },
   "outputs": [],
   "source": [
    "print(users.size)\n",
    "print(items.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGfqaoXu-pLI"
   },
   "outputs": [],
   "source": [
    "interaction_matrix = ratings.pivot(index='user_idx', columns='item_idx', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLEMFhUw-rQi",
    "outputId": "3e401cb3-e771-44c3-8431-2287e5cdf50a"
   },
   "outputs": [],
   "source": [
    "interaction_array= np.array(interaction_matrix)\n",
    "print(interaction_array)\n",
    "print('matrix dimensions : ', interaction_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTOrY6LzS1eR"
   },
   "outputs": [],
   "source": [
    "class UserItemDataset(Dataset):\n",
    "    def __init__(self, ratings):\n",
    "        self.ratings = ratings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.ratings.iloc[idx]\n",
    "        return {\n",
    "            'user_idx': torch.tensor(row['user_idx'], dtype=torch.long),\n",
    "            'item_idx': torch.tensor(row['item_idx'], dtype=torch.long),\n",
    "            'rating': torch.tensor(row['rating'], dtype=torch.float),\n",
    "        }\n",
    "\n",
    "# Create train, validation, and test splits (80% train, 10% validation, 10% test)\n",
    "train_size = int(len(ratings))\n",
    "val_size = int(0 * len(ratings))\n",
    "# test_size = len(ratings) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(ratings, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for batching\n",
    "train_loader = DataLoader(UserItemDataset(ratings.iloc[train_dataset.indices]), batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(UserItemDataset(ratings.iloc[val_dataset.indices]), batch_size=32, shuffle= True)\n",
    "# test_loader = DataLoader(UserItemDataset(ratings.iloc[test_dataset.indices]), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMgM9RCLS-em"
   },
   "outputs": [],
   "source": [
    "class MFModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size):\n",
    "        super(MFModel, self).__init__()\n",
    "        # Create embedding layers for users and items\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        # Get user and item embeddings\n",
    "        user_embedding = self.user_embedding(user_ids)\n",
    "        item_embedding = self.item_embedding(item_ids)\n",
    "        # Compute the dot product between user and item embeddings\n",
    "        dot_product = (user_embedding * item_embedding).sum(dim=1)\n",
    "        return dot_product\n",
    "\n",
    "# Initialize the model with number of users, items, and the embedding size\n",
    "num_users = len(users)\n",
    "num_items = len(items)\n",
    "embedding_size = 50  # This is a tunable hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqzhlDhES_M5"
   },
   "outputs": [],
   "source": [
    "mf_model1 = MFModel(num_users, num_items, embedding_size).to(device)\n",
    "optimizer = optim.Adam(mf_model1.parameters(), lr=0.001)  # Adam optimizer\n",
    "loss_fn = nn.MSELoss()  # Loss function (Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aF4Vor3dTCsI"
   },
   "outputs": [],
   "source": [
    "def train_mf_model(model, train_loader, optimizer, criterion, num_epochs=10):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            user_ids = batch['user_idx'].to(device)\n",
    "            item_ids = batch['item_idx'].to(device)\n",
    "            ratings = batch['rating'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Zero the gradients\n",
    "            preds = model(user_ids, item_ids)  # Forward pass\n",
    "            loss = criterion(preds, ratings)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Gradient descent step\n",
    "            total_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894
    },
    "id": "J_nVp17UTF2o",
    "outputId": "e5dc2038-eccf-439f-fb3e-faa2567b5816"
   },
   "outputs": [],
   "source": [
    "train_mf_model(mf_model1, train_loader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9TudjFxsTJUq"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    user_embeddings = mf_model1.user_embedding.weight.cpu().numpy()\n",
    "    item_embeddings = mf_model1.item_embedding.weight.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9X8Dn7KTMLq"
   },
   "outputs": [],
   "source": [
    "def create_graph_data(ratings,num_users,user_embeddings,item_embeddings):\n",
    "    user_item_edges = ratings[['user_idx', 'item_idx']].values.T  # Create edges between user-item pairs\n",
    "\n",
    "    user_item_edges[1] += num_users\n",
    "\n",
    "    # Create edge index (format required by torch_geometric)\n",
    "    edge_index = torch.tensor(user_item_edges, dtype=torch.long)\n",
    "\n",
    "    # Concatenate user and item embeddings to form node features\n",
    "    node_features = torch.cat([torch.tensor(user_embeddings, dtype=torch.float), torch.tensor(item_embeddings, dtype=torch.float)], dim=0)\n",
    "\n",
    "    print(node_features.shape)\n",
    "    print(user_item_edges.shape)\n",
    "    print(user_item_edges)\n",
    "\n",
    "    # Create the PyTorch Geometric data object (x: node features, edge_index: graph edges)\n",
    "    train_graph_data = Data(x=node_features, edge_index=edge_index)\n",
    "    return train_graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZvMir2qTMvi",
    "outputId": "996f5f34-1aab-41e8-c08a-7c743921a168"
   },
   "outputs": [],
   "source": [
    "train_graph_data = create_graph_data(ratings,num_users,user_embeddings,item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZnlguav_GoE"
   },
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCNModel, self).__init__()\n",
    "        # First graph convolutional layer\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        # Second graph convolutional layer\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Forward pass through the first graph convolutional layer\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)  # Apply ReLU non-linearity\n",
    "        # Forward pass through the second graph convolutional layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzGkvDQg_J7v"
   },
   "outputs": [],
   "source": [
    "model1 = GCNModel(in_channels=embedding_size, hidden_channels=64, out_channels=32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2TwdIWb_LmW"
   },
   "outputs": [],
   "source": [
    "gcn_optimizer = optim.Adam(model1.parameters(), lr=0.01)\n",
    "gcn_loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ntiWG2s_N2e"
   },
   "outputs": [],
   "source": [
    "def train_gcn_model(model, train_graph, optimizer, criterion, interaction_matrix,num_epochs=30):\n",
    "    model.train()  # Set model to training mode\n",
    "    user_embed=[]\n",
    "    item_embed=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        output = model(train_graph)  # Forward pass through the GCN\n",
    "\n",
    "\n",
    "        #print('output dimension',output.shape)\n",
    "        # Assuming user_idx and item_idx are indices of user-item pairs\n",
    "        user_indices = ratings['user_idx'].unique()  # Indices for users\n",
    "        item_indices = ratings['item_idx'].unique()  # Indices for items\n",
    "\n",
    "\n",
    "        #print('user indices dimension check',user_indices.shape)\n",
    "        #print('item indices dimension check',item_indices.shape)\n",
    "        # Get embeddings for the relevant user-item pairs\n",
    "        user_embeddings = output[user_indices]  # Shape: (N, embedding_size)\n",
    "        item_embeddings = output[item_indices + num_users]  # Shift by num_users for items\n",
    "\n",
    "        # Compute predicted ratings\n",
    "        predicted_ratings = torch.matmul(user_embeddings, item_embeddings.T) # Dot product\n",
    "\n",
    "        # Get target ratings from interaction matrix\n",
    "        interaction_tensor = torch.tensor(interaction_matrix.values, dtype=torch.float32)\n",
    "        target= interaction_tensor\n",
    "        #target = interaction_tensor[user_indices, item_indices].view(-1)  # Flatten to match\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(predicted_ratings, target)\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Gradient descent step\n",
    "\n",
    "        user_embed= user_embeddings\n",
    "        item_embed= item_embeddings\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "    return user_embed, item_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BJ46r33u_OTr",
    "outputId": "ef126a41-0513-4473-fd98-5fc2082ab32d"
   },
   "outputs": [],
   "source": [
    "user_embeddings, item_embeddings= train_gcn_model(model1, train_graph_data, gcn_optimizer, gcn_loss_fn, interaction_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPXwSycf_QhY",
    "outputId": "96d68520-e3bd-40a5-8544-a77d6e58a8da"
   },
   "outputs": [],
   "source": [
    "print(user_embeddings)\n",
    "print(user_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc4dNb8S_Scs",
    "outputId": "e0c3a228-7fa5-49d2-f816-53d3ffaf423f"
   },
   "outputs": [],
   "source": [
    "print(item_embeddings)\n",
    "print(item_embeddings.shape)\n",
    "old_item_embeddings= item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7PDqhGq_T9J"
   },
   "outputs": [],
   "source": [
    "def evaluate_gcn_model(model, user_embeddings, item_embeddings, interaction_matrix):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "\n",
    "        predicted_ratings = torch.matmul(user_embeddings, item_embeddings.T)\n",
    "        interaction_tensor = torch.tensor(interaction_matrix.values, dtype=torch.float32)\n",
    "        target= interaction_tensor\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(target, predicted_ratings))  # Compute RMSE\n",
    "        print(f'RMSE: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmZEYV0E_nD-"
   },
   "outputs": [],
   "source": [
    "def predict_new_user_rating(item_embeddings, masked_array, num_users=num_users):\n",
    "    item_embeddings = item_embeddings.detach().numpy()\n",
    "    masked_array = np.array(masked_array, dtype=np.float32)\n",
    "\n",
    "    masked_array = masked_array.reshape(-1, 1)  # Shape: (num_items, 1)\n",
    "    weighted_sum = np.sum(item_embeddings * masked_array, axis=0)\n",
    "    sum_of_weights = np.sum(masked_array)\n",
    "    new_user_embedding = weighted_sum / sum_of_weights\n",
    "    predicted_ratings = np.dot(item_embeddings, new_user_embedding)\n",
    "\n",
    "    return predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tz2QI3xC_q1O"
   },
   "outputs": [],
   "source": [
    "def prediction_test(num_users, interaction_array, item_embeddings):\n",
    "    metric=0\n",
    "    for i in range(len(interaction_array) - num_users, len(interaction_array)):\n",
    "        normal_test = interaction_array[i]\n",
    "        non_zero_indices = np.nonzero(normal_test)[0]\n",
    "        num_values_to_keep = len(non_zero_indices) // 2\n",
    "        selected_indices = np.random.choice(non_zero_indices, size=num_values_to_keep, replace=False)\n",
    "        masked_array = np.zeros_like(normal_test)\n",
    "        masked_array[selected_indices] = normal_test[selected_indices]\n",
    "        prediction = predict_new_user_rating(item_embeddings, masked_array)\n",
    "        prediction= np.clip(prediction, 0, 5)\n",
    "        rmse = np.sqrt(np.mean((prediction - normal_test) ** 2))\n",
    "        metric+= rmse\n",
    "    return metric/num_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNDmcH2GDMXa"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5XaZWT63_uUQ",
    "outputId": "f8852c27-8f17-4c13-f9a8-089f944cac26"
   },
   "outputs": [],
   "source": [
    "evaluate_gcn_model(model1, user_embeddings, item_embeddings,  interaction_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycfDDE5LDVt1"
   },
   "source": [
    "RECNORMAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQOH7Kfx_wZS",
    "outputId": "94deee95-6262-4c8c-b2e3-320c0534c3d9"
   },
   "outputs": [],
   "source": [
    "print(prediction_test(50, interaction_array, old_item_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE02PJExGMeC"
   },
   "source": [
    "# PHASE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoeQypng-y4a"
   },
   "outputs": [],
   "source": [
    "# Encoder: Maps interaction matrix to latent space\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ioYc8nOh-62k"
   },
   "outputs": [],
   "source": [
    "# Generator: Generates perturbed interactions\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim),\n",
    "            nn.Tanh(),  # Output perturbations in range [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3bNivcd-88M"
   },
   "outputs": [],
   "source": [
    "def train_encoder_generator(encoder, generator, interaction_matrix, num_epochs=20, batch_size=61, lr=0.001, lambda_reg=0.1):\n",
    "    e_optimizer = torch.optim.Adam(encoder.parameters(), lr=lr)\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "    mse_loss = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(0, len(interaction_matrix), batch_size):\n",
    "            # Get batch of data\n",
    "            real_data = interaction_matrix[i:i + batch_size]\n",
    "            batch_size = real_data.size(0)\n",
    "\n",
    "            # Encode real data to latent space\n",
    "            latent_real = encoder(real_data)\n",
    "\n",
    "            # Generate perturbations\n",
    "            perturbations = generator(latent_real)\n",
    "\n",
    "            # Create perturbed matrix\n",
    "            perturbed_data = real_data + perturbations\n",
    "            perturbed_data = torch.clamp(perturbed_data, 0, 5)  # Clip to valid range [0, 5]\n",
    "\n",
    "            # Loss: Reconstruction + Regularization\n",
    "            recon_loss = mse_loss(perturbed_data, real_data)\n",
    "            reg_loss = lambda_reg * torch.norm(perturbations, p=2)\n",
    "            loss = recon_loss + reg_loss\n",
    "\n",
    "            # Backward and optimization\n",
    "            e_optimizer.zero_grad()\n",
    "            g_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            e_optimizer.step()\n",
    "            g_optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return encoder, generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gT1eyFM9BmND",
    "outputId": "1f74f726-9d89-4ad0-8392-ad98e2175445"
   },
   "outputs": [],
   "source": [
    "interaction_matrix= torch.tensor(interaction_array, dtype=torch.float32)\n",
    "print(interaction_matrix)\n",
    "interaction_matrix = interaction_matrix.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHGY8RZOB1rd"
   },
   "outputs": [],
   "source": [
    "num_items = interaction_matrix.size(1)\n",
    "latent_dim = 8\n",
    "\n",
    "# Initialize encoder and generator\n",
    "encoder = Encoder(input_dim=num_items, latent_dim=latent_dim)\n",
    "generator = Generator(latent_dim=latent_dim, output_dim=num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Td4X4LWUCDM_",
    "outputId": "37e4a9a4-f044-4199-9946-e8895662f82a"
   },
   "outputs": [],
   "source": [
    "# Train the encoder and generator\n",
    "encoder, generator = train_encoder_generator(\n",
    "    encoder, generator, interaction_matrix, num_epochs=10, batch_size=61, lr=0.01, lambda_reg=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75ekP2V1CHSf",
    "outputId": "04ecf634-9eed-4b20-f6f7-345203149aaf"
   },
   "outputs": [],
   "source": [
    "# Generate perturbed interactions\n",
    "with torch.no_grad():\n",
    "    latent_real = encoder(interaction_matrix)\n",
    "    perturbations = generator(latent_real)\n",
    "    perturbed_matrix = torch.clamp(interaction_matrix + perturbations*10, 0, 5)\n",
    "\n",
    "print(\"Original Interaction Matrix:\")\n",
    "print(interaction_matrix)\n",
    "\n",
    "print(\"Perturbed Interaction Matrix:\")\n",
    "print(perturbed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJ-AExvYBJ2V"
   },
   "outputs": [],
   "source": [
    "interaction_array_manipulated= np.array(perturbed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjjfG48L_zvh",
    "outputId": "f10a57aa-d754-4b8c-b4c7-b146e151a551"
   },
   "outputs": [],
   "source": [
    "user_indices, item_indices = np.nonzero(interaction_array_manipulated)  # Get indices of non-zero elements\n",
    "\n",
    "# Retrieve the corresponding ratings from interaction_array\n",
    "ratings = interaction_array_manipulated[user_indices, item_indices]\n",
    "\n",
    "# Create a DataFrame similar to the original ratings DataFrame\n",
    "reconstructed_ratings = pd.DataFrame({\n",
    "    'user_idx': user_indices,\n",
    "    'item_idx': item_indices,\n",
    "    'rating': ratings\n",
    "})\n",
    "\n",
    "# Print to verify\n",
    "print(reconstructed_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFVgsSTnATJV"
   },
   "outputs": [],
   "source": [
    "ratings = reconstructed_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5_8pV6PAY1R"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(ratings))\n",
    "val_size = int(0 * len(ratings))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(ratings, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRIiRjLiAaXr"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(UserItemDataset(ratings.iloc[train_dataset.indices]), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yO_WuXf1AcUQ"
   },
   "outputs": [],
   "source": [
    "users = ratings['user_idx'].unique()\n",
    "items = ratings['item_idx'].unique()\n",
    "\n",
    "# Create mappings from user/item IDs to indices (used for embedding)\n",
    "user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
    "item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
    "\n",
    "# Convert user and item IDs in ratings to indices\n",
    "ratings['user_idx'] = ratings['user_idx'].apply(lambda x: user_to_idx[x])\n",
    "ratings['item_idx'] = ratings['item_idx'].apply(lambda x: item_to_idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRjKdvp1AtzT"
   },
   "outputs": [],
   "source": [
    "num_users = len(users)\n",
    "num_items = len(items)\n",
    "embedding_size = 50  # This is a tunable hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htfPyGqfAxI3"
   },
   "outputs": [],
   "source": [
    "mf_model2 = MFModel(num_users, num_items, embedding_size).to(device)\n",
    "optimizer = optim.Adam(mf_model2.parameters(), lr=0.001)  # Adam optimizer\n",
    "loss_fn = nn.MSELoss()  # Loss function (Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9vhJnuiAy5_",
    "outputId": "10e0dced-8746-4253-ef29-477f36138b99"
   },
   "outputs": [],
   "source": [
    "print(num_users, num_items, mf_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "-OLk3an4A0kI",
    "outputId": "4f021ca5-a84e-4739-9175-fb64cc0ebb23"
   },
   "outputs": [],
   "source": [
    "train_mf_model(mf_model2, train_loader, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGSqhbqpA2XN"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    user_embeddings = mf_model2.user_embedding.weight.cpu().numpy()\n",
    "    item_embeddings = mf_model2.item_embedding.weight.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lH6fihzA4I_",
    "outputId": "90429b1c-2409-43db-f5a9-634a58999740"
   },
   "outputs": [],
   "source": [
    "print(user_embeddings.shape)\n",
    "print(user_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lawL7jYOA51_",
    "outputId": "a3e06ad2-a5d9-4918-dc42-0239dfe18cb3"
   },
   "outputs": [],
   "source": [
    "train_graph_data = create_graph_data(ratings,num_users,user_embeddings,item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwdVRZKbA75W"
   },
   "outputs": [],
   "source": [
    "model2 = GCNModel(in_channels=embedding_size, hidden_channels=64, out_channels=32).to(device)\n",
    "gcn_optimizer = optim.Adam(model2.parameters(), lr=0.01)\n",
    "gcn_loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqkFi2WlA9or"
   },
   "outputs": [],
   "source": [
    "interaction_matrix_manipulated = ratings.pivot(index='user_idx', columns='item_idx', values='rating').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PEValFyzA_xJ",
    "outputId": "41e77105-26da-440f-e99b-a7615485b74a"
   },
   "outputs": [],
   "source": [
    "user_embeddings, item_embeddings= train_gcn_model(model2, train_graph_data, gcn_optimizer, gcn_loss_fn, interaction_matrix_manipulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m6mQ0ndvBBgO",
    "outputId": "779b441e-18b3-40a4-f4a3-e61753f6f619"
   },
   "outputs": [],
   "source": [
    "evaluate_gcn_model(model2, user_embeddings, item_embeddings,  interaction_matrix_manipulated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTB41AqDDejU"
   },
   "source": [
    "RECSECURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9NNBOYDBDUV",
    "outputId": "ed5fc835-95e7-4c6c-b271-0d71e95cbb98"
   },
   "outputs": [],
   "source": [
    "print(prediction_test(50, interaction_array_manipulated, item_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eBTm1ozDiGe"
   },
   "source": [
    "RECMANI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGjdKe0IBFRm",
    "outputId": "8e1c4e47-81e1-4984-80fe-392577800dfb"
   },
   "outputs": [],
   "source": [
    "print(prediction_test(50, interaction_array_manipulated, old_item_embeddings))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
