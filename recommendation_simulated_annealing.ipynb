{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZP2hZINH9F5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import warnings\n",
        "import copy\n",
        "import random\n",
        "from keras import layers, models\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDosArdZH9F6"
      },
      "outputs": [],
      "source": [
        "def anneal(alpha, mask_a, d=2, lower_bound=20, upper_bound=10):\n",
        "    alpha = alpha.copy()\n",
        "    mask_b = np.random.choice([True, False], size=alpha.shape)\n",
        "    mask = mask_a ^ mask_b\n",
        "    step = np.random.randint(0, d+1, size=alpha.shape)/225.\n",
        "    start_h = 0\n",
        "    end_h = 1\n",
        "    start_w = np.random.randint(0, lower_bound)\n",
        "    end_w = np.random.randint(len(alpha) - upper_bound, len(alpha))\n",
        "    masksliced = np.zeros(alpha.shape, dtype=bool)\n",
        "    masksliced[start_w:end_w] = mask[start_w:end_w]\n",
        "    alpha[masksliced] += step[masksliced]\n",
        "    return alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7SOOQXrH9F7"
      },
      "outputs": [],
      "source": [
        "def rmse_score(model, user_ind,user_embeddings, item_embeddings, alpha):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        alpha= alpha.reshape(-1)\n",
        "        predicted_ratings = torch.matmul(user_embeddings[user_ind], item_embeddings.T)\n",
        "        interaction_tensor = torch.tensor(alpha, dtype=torch.float32)\n",
        "        target= interaction_tensor\n",
        "        rmse = np.sqrt(mean_squared_error(target, predicted_ratings))  # Compute RMSE\n",
        "\n",
        "    return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDzoqahlH9F7"
      },
      "outputs": [],
      "source": [
        "def fitness(user_embeddings, item_embeddings, alpha_population, model, lambda_value = 0.1):\n",
        "    fitness_values = []\n",
        "    for alpha_ind, alpha in alpha_population:\n",
        "        # here alpha represents that one pparticular user's interaction with all the items\n",
        "        # alpha_population represents manipulated interaction matrix for some users\n",
        "\n",
        "        error = lambda_value * rmse_score(model, alpha_ind ,user_embeddings, item_embeddings, alpha)\n",
        "        alpha_fitness = 1 + error - np.linalg.norm(alpha)\n",
        "        fitness_values.append(abs(np.max(alpha_fitness)))\n",
        "    return fitness_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YO6i8uzgH9F7"
      },
      "outputs": [],
      "source": [
        "def twoplayergame_sa(user_embeddings, item_embeddings, interaction_matrix, model):\n",
        "    maxpayoff = 0\n",
        "    exitloop = False\n",
        "    Tmax = 10\n",
        "    Tmin = 5\n",
        "    v = 50\n",
        "    p = 0.2\n",
        "    mask = np.random.choice([True,False], size=interaction_matrix[0].shape)\n",
        "    Tcurr = Tmax\n",
        "    population = [(i,interaction_matrix[i]) for i in range(interaction_matrix.shape[0])]\n",
        "    random.shuffle(population)\n",
        "    pop_size = len(population) // 3\n",
        "    ac = population[:pop_size].copy()\n",
        "    ag = population[pop_size:2*pop_size].copy()\n",
        "    an = population[2*pop_size:].copy()\n",
        "    evalc = fitness(user_embeddings, item_embeddings, ac, model)\n",
        "    maxpayoff = max(fitness(user_embeddings, item_embeddings, ag, model))\n",
        "    while not exitloop:\n",
        "        evalg = fitness(user_embeddings, item_embeddings, ag,model)\n",
        "        curr_index = np.argmax(evalg)\n",
        "        currpayoff = evalg[curr_index]\n",
        "        print(\"The current Payoff is:\",currpayoff)\n",
        "        if abs(currpayoff - maxpayoff) < 0.1:\n",
        "            maxpayoff = currpayoff\n",
        "            while Tcurr >= Tmin:\n",
        "                i = 1\n",
        "                while i <= v:\n",
        "                    temp = []\n",
        "                    for ind, interaction in ac:\n",
        "                        temp.append((ind,anneal(interaction,mask)))\n",
        "                    an = temp.copy()\n",
        "                    evaln = fitness(user_embeddings, item_embeddings, an,model)\n",
        "                    if max(evaln) > max(evalc):\n",
        "                        ac = an.copy()\n",
        "                        evalc = evaln.copy()\n",
        "                        if max(evalg) < max(evaln):\n",
        "                            ag = an.copy()\n",
        "                            evalg = evaln.copy()\n",
        "                    else:\n",
        "                        if np.random.random() <= np.exp((max(evaln) - max(evalc)) / Tcurr):\n",
        "                            ac = an.copy()\n",
        "                            evalc = evaln.copy()\n",
        "                    i += 1\n",
        "                Tcurr *= p\n",
        "            ag = ac.copy()\n",
        "        else:\n",
        "            exitloop = True\n",
        "    return ag[np.argmax(fitness(user_embeddings, item_embeddings, ag, model))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H49aTEqqH9F8"
      },
      "outputs": [],
      "source": [
        "def generate_manipulated_data(matrix, A_s):\n",
        "    #here A_s is manippulated data for some users\n",
        "    alphas=[]\n",
        "    for i in range(len(A_s)):\n",
        "        alphas.append(A_s[i][1])\n",
        "    print(alphas)\n",
        "    X_manipulated = np.concatenate([matrix, alphas], axis=0)\n",
        "    return X_manipulated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHDZ_toIH9F8"
      },
      "outputs": [],
      "source": [
        "def adversarial_manipulation(user_embeddings, item_embeddings, interaction_matrix, model,M):\n",
        "    A_s = []\n",
        "    for i in range(1, M+1):\n",
        "        a_i = twoplayergame_sa(user_embeddings, item_embeddings, interaction_matrix, model)\n",
        "        A_s.append(a_i)\n",
        "\n",
        "    interaction_matrix_manipulated= generate_manipulated_data(interaction_matrix, A_s)\n",
        "    return interaction_matrix_manipulated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shyuj8NZH9F8"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOtUXdGuH9F9"
      },
      "source": [
        "1. Normal - with the normal interaction matrix we generate recommendations for some existing user/ new user\n",
        "2. manipulated -\n",
        "3. secure -  train the gcn with adversarial interaction matrix and generate recommendations for some existing user/ new user\n",
        "\n",
        "The metric can be rmse or the top k predictions produced in each case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "elfx4152H9F9",
        "outputId": "2cfd1b04-4d83-4e21-d71a-d14358ae44f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m61.4/63.1 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch_geometric) (0.2.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCZLkYhkH9F-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Set device: use GPU if available, otherwise fallback to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define base path to save trained models and other outputs\n",
        "save_base_path = \"/path/to/save\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPmB_L4vH9F-"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuQrsiEJH9F-",
        "outputId": "c687e46d-5f48-48e5-ad7a-3aa38e21ef8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating  timestamp\n",
            "0       1        1     4.0  964982703\n",
            "1       1        3     4.0  964981247\n",
            "2       1        6     4.0  964982224\n",
            "3       1       47     5.0  964983815\n",
            "4       1       50     5.0  964982931\n",
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1                   Adventure|Children|Fantasy  \n",
            "2                               Comedy|Romance  \n",
            "3                         Comedy|Drama|Romance  \n",
            "4                                       Comedy  \n"
          ]
        }
      ],
      "source": [
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "\n",
        "# Download the dataset\n",
        "response = requests.get(url)\n",
        "zip_file = zipfile.ZipFile(BytesIO(response.content))\n",
        "\n",
        "# Extract the ratings and movies CSV files\n",
        "ratings = pd.read_csv(zip_file.open('ml-latest-small/ratings.csv'))\n",
        "movies = pd.read_csv(zip_file.open('ml-latest-small/movies.csv'))\n",
        "\n",
        "# Preview the datasets\n",
        "print(ratings.head())\n",
        "print(movies.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eeZxhObH9F-"
      },
      "outputs": [],
      "source": [
        "# Get unique users and items from the ratings dataset\n",
        "users = ratings['userId'].unique()\n",
        "items = ratings['movieId'].unique()\n",
        "\n",
        "# Create mappings from user/item IDs to indices (used for embedding)\n",
        "user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
        "item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
        "\n",
        "# Convert user and item IDs in ratings to indices\n",
        "ratings['user_idx'] = ratings['userId'].apply(lambda x: user_to_idx[x])\n",
        "ratings['item_idx'] = ratings['movieId'].apply(lambda x: item_to_idx[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc_FqO7VH9F-",
        "outputId": "f32b1184-f10b-4b45-d71d-7233138d6691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "610\n",
            "9724\n"
          ]
        }
      ],
      "source": [
        "print(users.size)\n",
        "print(items.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x23zzIcgH9F-",
        "outputId": "f4171362-b007-483e-e668-f8f0cfc7a1aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        userId  movieId  rating   timestamp  user_idx  item_idx\n",
            "0            1        1     4.0   964982703         0         0\n",
            "1            1        3     4.0   964981247         0         1\n",
            "2            1        6     4.0   964982224         0         2\n",
            "3            1       47     5.0   964983815         0         3\n",
            "4            1       50     5.0   964982931         0         4\n",
            "...        ...      ...     ...         ...       ...       ...\n",
            "100831     610   166534     4.0  1493848402       609      3120\n",
            "100832     610   168248     5.0  1493850091       609      2035\n",
            "100833     610   168250     5.0  1494273047       609      3121\n",
            "100834     610   168252     5.0  1493846352       609      1392\n",
            "100835     610   170875     3.0  1493846415       609      2873\n",
            "\n",
            "[100836 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "print(ratings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upMOEdBEH9F-"
      },
      "outputs": [],
      "source": [
        "# Create a pivot table where rows are users, columns are items, and values are ratings\n",
        "interaction_matrix = ratings.pivot(index='user_idx', columns='item_idx', values='rating').fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRfFCwDGH9F-",
        "outputId": "f99dfd43-5ad3-4d44-8296-afa07a69b689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.  4.  4.  ... 0.  0.  0. ]\n",
            " [0.  0.  0.  ... 0.  0.  0. ]\n",
            " [0.  0.  0.  ... 0.  0.  0. ]\n",
            " ...\n",
            " [2.5 2.  0.  ... 0.  0.  0. ]\n",
            " [3.  0.  0.  ... 0.  0.  0. ]\n",
            " [5.  0.  5.  ... 3.  3.5 3.5]]\n",
            "matrix dimensions :  (610, 9724)\n"
          ]
        }
      ],
      "source": [
        "interaction_array= np.array(interaction_matrix)\n",
        "print(interaction_array)\n",
        "print('matrix dimensions : ', interaction_array.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLcxkH3uH9F_"
      },
      "outputs": [],
      "source": [
        "class UserItemDataset(Dataset):\n",
        "    def __init__(self, ratings):\n",
        "        self.ratings = ratings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.ratings.iloc[idx]\n",
        "        return {\n",
        "            'user_idx': torch.tensor(row['user_idx'], dtype=torch.long),\n",
        "            'item_idx': torch.tensor(row['item_idx'], dtype=torch.long),\n",
        "            'rating': torch.tensor(row['rating'], dtype=torch.float),\n",
        "        }\n",
        "\n",
        "# Create train, validation, and test splits (80% train, 10% validation, 10% test)\n",
        "train_size = int(len(ratings))\n",
        "val_size = int(0 * len(ratings))\n",
        "# test_size = len(ratings) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(ratings, [train_size, val_size])\n",
        "\n",
        "# Create data loaders for batching\n",
        "train_loader = DataLoader(UserItemDataset(ratings.iloc[train_dataset.indices]), batch_size=32, shuffle=True)\n",
        "# val_loader = DataLoader(UserItemDataset(ratings.iloc[val_dataset.indices]), batch_size=32, shuffle= True)\n",
        "# test_loader = DataLoader(UserItemDataset(ratings.iloc[test_dataset.indices]), batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKApT5wiH9F_"
      },
      "outputs": [],
      "source": [
        "class MFModel(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_size):\n",
        "        super(MFModel, self).__init__()\n",
        "        # Create embedding layers for users and items\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
        "\n",
        "    def forward(self, user_ids, item_ids):\n",
        "        # Get user and item embeddings\n",
        "        user_embedding = self.user_embedding(user_ids)\n",
        "        item_embedding = self.item_embedding(item_ids)\n",
        "        # Compute the dot product between user and item embeddings\n",
        "        dot_product = (user_embedding * item_embedding).sum(dim=1)\n",
        "        return dot_product\n",
        "\n",
        "# Initialize the model with number of users, items, and the embedding size\n",
        "num_users = len(users)\n",
        "num_items = len(items)\n",
        "embedding_size = 50  # This is a tunable hyperparameter\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mf_model1 = MFModel(num_users, num_items, embedding_size).to(device)\n",
        "optimizer = optim.Adam(mf_model1.parameters(), lr=0.001)  # Adam optimizer\n",
        "loss_fn = nn.MSELoss()  # Loss function (Mean Squared Error)"
      ],
      "metadata": {
        "id": "9YKB4hIkI6NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_-TEWvNH9F_",
        "outputId": "6bf5964d-02a0-4ca4-eaa5-6a9929420978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "610 9724 MFModel(\n",
            "  (user_embedding): Embedding(610, 50)\n",
            "  (item_embedding): Embedding(9724, 50)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(num_users, num_items, mf_model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMCMJnQhH9F_"
      },
      "outputs": [],
      "source": [
        "def train_mf_model(model, train_loader, optimizer, criterion, num_epochs=10):\n",
        "    model.train()  # Set the model to training mode\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            user_ids = batch['user_idx'].to(device)\n",
        "            item_ids = batch['item_idx'].to(device)\n",
        "            ratings = batch['rating'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the gradients\n",
        "            preds = model(user_ids, item_ids)  # Forward pass\n",
        "            loss = criterion(preds, ratings)  # Compute loss\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Gradient descent step\n",
        "            total_loss += loss.item()  # Accumulate loss\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mf_model(mf_model1, train_loader, optimizer, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qUj1bgRJJnC",
        "outputId": "eaec4aa8-7a96-44a8-88cc-40ed8c3276a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 54.6969\n",
            "Epoch 2/10, Loss: 37.4366\n",
            "Epoch 3/10, Loss: 26.6908\n",
            "Epoch 4/10, Loss: 19.7055\n",
            "Epoch 5/10, Loss: 14.5891\n",
            "Epoch 6/10, Loss: 10.2549\n",
            "Epoch 7/10, Loss: 6.6135\n",
            "Epoch 8/10, Loss: 4.1228\n",
            "Epoch 9/10, Loss: 2.6567\n",
            "Epoch 10/10, Loss: 1.8019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Veluz8PwH9F_"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    user_embeddings = mf_model1.user_embedding.weight.cpu().numpy()\n",
        "    item_embeddings = mf_model1.item_embedding.weight.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnNLRizPH9F_",
        "outputId": "2d7486c2-680d-443b-a1b1-808f4550fb07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(610, 50)\n",
            "[[ 1.5477024e-04  4.4074067e-01  4.0332235e-02 ... -5.9118766e-01\n",
            "   1.7145234e-01 -9.1096663e-01]\n",
            " [ 2.7443569e-02 -6.9788116e-01  1.9023906e-01 ...  3.6470050e-01\n",
            "  -1.2387406e+00 -4.6131521e-01]\n",
            " [ 2.5046322e-01  2.5560412e-01 -1.5024363e-01 ... -1.9373876e+00\n",
            "  -4.2474613e-01 -1.0763760e+00]\n",
            " ...\n",
            " [-1.6998166e-01  5.2733362e-01  2.1600449e-01 ... -3.1336018e-01\n",
            "   2.3594224e-01  9.0743750e-02]\n",
            " [ 9.0982920e-01  1.0660665e-01  1.7177416e+00 ... -5.4283381e-01\n",
            "   8.1047809e-01 -3.6990464e-02]\n",
            " [ 1.8971203e-02  6.7724478e-01  7.9474516e-02 ... -3.3001146e-01\n",
            "  -1.9065486e-01  3.2382765e-01]]\n"
          ]
        }
      ],
      "source": [
        "print(user_embeddings.shape)\n",
        "print(user_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OW05ZMQcH9F_"
      },
      "outputs": [],
      "source": [
        "def create_graph_data(ratings,num_users,user_embeddings,item_embeddings):\n",
        "    user_item_edges = ratings[['user_idx', 'item_idx']].values.T  # Create edges between user-item pairs\n",
        "\n",
        "    user_item_edges[1] += num_users\n",
        "\n",
        "    # Create edge index (format required by torch_geometric)\n",
        "    edge_index = torch.tensor(user_item_edges, dtype=torch.long)\n",
        "\n",
        "    # Concatenate user and item embeddings to form node features\n",
        "    node_features = torch.cat([torch.tensor(user_embeddings, dtype=torch.float), torch.tensor(item_embeddings, dtype=torch.float)], dim=0)\n",
        "\n",
        "    print(node_features.shape)\n",
        "    print(user_item_edges.shape)\n",
        "    print(user_item_edges)\n",
        "\n",
        "    # Create the PyTorch Geometric data object (x: node features, edge_index: graph edges)\n",
        "    train_graph_data = Data(x=node_features, edge_index=edge_index)\n",
        "    return train_graph_data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_graph_data = create_graph_data(ratings,num_users,user_embeddings,item_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYDNmZNVMAVd",
        "outputId": "0852933b-8a0f-4c63-82f6-faabb34665fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10334, 50])\n",
            "(2, 100836)\n",
            "[[   0    0    0 ...  609  609  609]\n",
            " [ 610  611  612 ... 3731 2002 3483]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIQ7Wf5AH9F_"
      },
      "outputs": [],
      "source": [
        "class GCNModel(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCNModel, self).__init__()\n",
        "        # First graph convolutional layer\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        # Second graph convolutional layer\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # Forward pass through the first graph convolutional layer\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)  # Apply ReLU non-linearity\n",
        "        # Forward pass through the second graph convolutional layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6tGkR3CH9F_"
      },
      "outputs": [],
      "source": [
        "# Initialize the GCN model\n",
        "model1 = GCNModel(in_channels=embedding_size, hidden_channels=64, out_channels=32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qrkeq_cRH9GA"
      },
      "outputs": [],
      "source": [
        "gcn_optimizer = optim.Adam(model1.parameters(), lr=0.01)\n",
        "gcn_loss_fn = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TH1pAHLH9GA"
      },
      "outputs": [],
      "source": [
        "def train_gcn_model(model, train_graph, optimizer, criterion, interaction_matrix,num_epochs=30):\n",
        "    model.train()  # Set model to training mode\n",
        "    user_embed=[]\n",
        "    item_embed=[]\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        output = model(train_graph)  # Forward pass through the GCN\n",
        "\n",
        "\n",
        "        #print('output dimension',output.shape)\n",
        "        # Assuming user_idx and item_idx are indices of user-item pairs\n",
        "        user_indices = ratings['user_idx'].unique()  # Indices for users\n",
        "        item_indices = ratings['item_idx'].unique()  # Indices for items\n",
        "\n",
        "\n",
        "        #print('user indices dimension check',user_indices.shape)\n",
        "        #print('item indices dimension check',item_indices.shape)\n",
        "        # Get embeddings for the relevant user-item pairs\n",
        "        user_embeddings = output[user_indices]  # Shape: (N, embedding_size)\n",
        "        item_embeddings = output[item_indices + num_users]  # Shift by num_users for items\n",
        "\n",
        "        # Compute predicted ratings\n",
        "        predicted_ratings = torch.matmul(user_embeddings, item_embeddings.T) # Dot product\n",
        "\n",
        "        # Get target ratings from interaction matrix\n",
        "        interaction_tensor = torch.tensor(interaction_matrix.values, dtype=torch.float32)\n",
        "        target= interaction_tensor\n",
        "        #target = interaction_tensor[user_indices, item_indices].view(-1)  # Flatten to match\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(predicted_ratings, target)\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Gradient descent step\n",
        "\n",
        "        user_embed= user_embeddings\n",
        "        item_embed= item_embeddings\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
        "\n",
        "    return user_embed, item_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJUJ2RkBH9GA",
        "outputId": "5430f1a0-80f4-4c02-ca2f-35f88a86e360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 157.2139\n",
            "Epoch 2/30, Loss: 11.4264\n",
            "Epoch 3/30, Loss: 5.8486\n",
            "Epoch 4/30, Loss: 9.8361\n",
            "Epoch 5/30, Loss: 14.0040\n",
            "Epoch 6/30, Loss: 14.2494\n",
            "Epoch 7/30, Loss: 11.7604\n",
            "Epoch 8/30, Loss: 8.7397\n",
            "Epoch 9/30, Loss: 6.2388\n",
            "Epoch 10/30, Loss: 4.4234\n",
            "Epoch 11/30, Loss: 3.1859\n",
            "Epoch 12/30, Loss: 2.3583\n",
            "Epoch 13/30, Loss: 1.8039\n",
            "Epoch 14/30, Loss: 1.4260\n",
            "Epoch 15/30, Loss: 1.1638\n",
            "Epoch 16/30, Loss: 0.9766\n",
            "Epoch 17/30, Loss: 0.8380\n",
            "Epoch 18/30, Loss: 0.7333\n",
            "Epoch 19/30, Loss: 0.6533\n",
            "Epoch 20/30, Loss: 0.5915\n",
            "Epoch 21/30, Loss: 0.5427\n",
            "Epoch 22/30, Loss: 0.5040\n",
            "Epoch 23/30, Loss: 0.4729\n",
            "Epoch 24/30, Loss: 0.4475\n",
            "Epoch 25/30, Loss: 0.4266\n",
            "Epoch 26/30, Loss: 0.4092\n",
            "Epoch 27/30, Loss: 0.3945\n",
            "Epoch 28/30, Loss: 0.3821\n",
            "Epoch 29/30, Loss: 0.3714\n",
            "Epoch 30/30, Loss: 0.3622\n"
          ]
        }
      ],
      "source": [
        "user_embeddings, item_embeddings= train_gcn_model(model1, train_graph_data, gcn_optimizer, gcn_loss_fn, interaction_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lskzzxsKH9GA",
        "outputId": "2a8369fc-615e-466d-e349-e03849281c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1857, -0.0128,  0.1200,  ..., -0.1174, -0.0030, -0.0708],\n",
            "        [-0.1522,  0.4284,  0.2417,  ...,  0.2828, -0.1968,  0.0984],\n",
            "        [ 0.0252, -0.0926,  0.3362,  ...,  0.0628, -0.1684, -0.0068],\n",
            "        ...,\n",
            "        [ 0.0263, -0.0391,  0.1251,  ..., -0.0085, -0.0080, -0.0169],\n",
            "        [ 0.2150,  0.0108,  0.2129,  ..., -0.2333,  0.2984,  0.0202],\n",
            "        [ 0.0494,  0.0105,  0.1090,  ...,  0.0606, -0.0413,  0.0364]],\n",
            "       grad_fn=<IndexBackward0>)\n",
            "torch.Size([610, 32])\n"
          ]
        }
      ],
      "source": [
        "print(user_embeddings)\n",
        "print(user_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(item_embeddings)\n",
        "print(item_embeddings.shape)\n",
        "old_item_embeddings= item_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaV6s7uRjGVG",
        "outputId": "fa757e17-51a9-42e5-8e74-8e8166ecee16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-2.9757e-01,  3.9954e-01, -1.5570e-01,  ..., -6.5423e-01,\n",
            "          3.8565e-01,  1.0043e+00],\n",
            "        [-2.3310e-01,  4.5532e-01, -3.9908e-01,  ..., -3.0845e-01,\n",
            "          3.2284e-01,  3.0605e-01],\n",
            "        [-2.8209e-01,  6.5010e-01, -4.7004e-01,  ..., -4.9673e-01,\n",
            "          3.5249e-01,  7.1333e-01],\n",
            "        ...,\n",
            "        [ 2.9734e-02,  9.7946e-03,  1.2599e-01,  ...,  1.7633e-02,\n",
            "         -1.6950e-02,  2.4318e-02],\n",
            "        [ 1.5419e-01,  1.4447e-02,  1.1107e-01,  ...,  4.3029e-02,\n",
            "          8.9812e-03,  9.2749e-02],\n",
            "        [ 7.6198e-02, -9.7442e-04,  1.9572e-01,  ..., -3.4445e-02,\n",
            "         -3.1626e-02, -6.3794e-02]], grad_fn=<IndexBackward0>)\n",
            "torch.Size([9724, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJULtSHTH9GA"
      },
      "outputs": [],
      "source": [
        "def evaluate_gcn_model(model, user_embeddings, item_embeddings, interaction_matrix):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "\n",
        "        predicted_ratings = torch.matmul(user_embeddings, item_embeddings.T)\n",
        "        interaction_tensor = torch.tensor(interaction_matrix.values, dtype=torch.float32)\n",
        "        target= interaction_tensor\n",
        "\n",
        "        rmse = np.sqrt(mean_squared_error(target, predicted_ratings))  # Compute RMSE\n",
        "        print(f'RMSE: {rmse:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_new_user_rating(item_embeddings, masked_array, num_users=num_users):\n",
        "    item_embeddings = item_embeddings.detach().numpy()\n",
        "    masked_array = np.array(masked_array, dtype=np.float32)\n",
        "\n",
        "    masked_array = masked_array.reshape(-1, 1)  # Shape: (num_items, 1)\n",
        "    weighted_sum = np.sum(item_embeddings * masked_array, axis=0)\n",
        "    sum_of_weights = np.sum(masked_array)\n",
        "    new_user_embedding = weighted_sum / sum_of_weights\n",
        "    predicted_ratings = np.dot(item_embeddings, new_user_embedding)\n",
        "\n",
        "    return predicted_ratings"
      ],
      "metadata": {
        "id": "zyMyvKQcZ7X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_test(num_users, interaction_array, item_embeddings):\n",
        "    metric=0\n",
        "    for i in range(len(interaction_array) - num_users, len(interaction_array)):\n",
        "        normal_test = interaction_array[i]\n",
        "        non_zero_indices = np.nonzero(normal_test)[0]\n",
        "        num_values_to_keep = len(non_zero_indices) // 2\n",
        "        selected_indices = np.random.choice(non_zero_indices, size=num_values_to_keep, replace=False)\n",
        "        masked_array = np.zeros_like(normal_test)\n",
        "        masked_array[selected_indices] = normal_test[selected_indices]\n",
        "        prediction = predict_new_user_rating(item_embeddings, masked_array)\n",
        "        rmse = np.sqrt(np.mean((prediction - normal_test) ** 2))\n",
        "        metric+= rmse\n",
        "    return metric/num_users"
      ],
      "metadata": {
        "id": "nnwzBffw00cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "787-9GTBH9GA",
        "outputId": "3d36f0bb-8616-4a5d-af77-3b2bc6d831ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.6019\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on training data\n",
        "evaluate_gcn_model(model1, user_embeddings, item_embeddings,  interaction_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing for RECnormal"
      ],
      "metadata": {
        "id": "L_EuNyEXZu7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_test(50, interaction_array, old_item_embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSH4B2Sg2Ryi",
        "outputId": "5c44465d-9c7f-40ee-b8ee-27afdb84ba2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1991706365211101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normal_test = interaction_array[:50]"
      ],
      "metadata": {
        "id": "09fR5qvmZuLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_values_to_keep = 20\n",
        "# non_zero_indices = np.nonzero(normal_test)[0]\n",
        "# selected_indices = np.random.choice(non_zero_indices, size=num_values_to_keep, replace=False)\n",
        "# masked_array = np.zeros_like(normal_test)\n",
        "# masked_array[selected_indices] = normal_test[selected_indices]\n",
        "# print(masked_array)"
      ],
      "metadata": {
        "id": "SPZy295kakuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction = predict_new_user_rating(old_item_embeddings, masked_array)"
      ],
      "metadata": {
        "id": "kDc64Tu9awcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rmse = np.sqrt(np.mean((prediction - normal_test) ** 2))\n",
        "# print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "id": "TjtWDakZa2ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpE7iN7dH9GB",
        "outputId": "6c47a559-4a85-4a85-a5f2-225d0ca100df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current Payoff is: 129.5894561508261\n",
            "The current Payoff is: 187.35015118447063\n",
            "The current Payoff is: 120.83751022372473\n",
            "The current Payoff is: 187.35444951561834\n",
            "The current Payoff is: 135.5049618286381\n",
            "The current Payoff is: 142.10198282994554\n",
            "The current Payoff is: 159.49090621273086\n",
            "The current Payoff is: 125.21516606879946\n",
            "The current Payoff is: 181.5549168362805\n",
            "The current Payoff is: 142.11454471616645\n",
            "[array([4.        , 4.00888889, 3.01777778, ..., 0.01333333, 0.00888889,\n",
            "       0.        ]), array([4.00888889, 4.01777778, 3.        , ..., 0.04444444, 0.03111111,\n",
            "       0.        ]), array([3.00444444, 1.52222222, 4.51777778, ..., 0.03111111, 0.        ,\n",
            "       0.        ]), array([4.02222222, 0.00444444, 4.00888889, ..., 0.        , 0.00444444,\n",
            "       0.        ]), array([3.00888889, 1.52222222, 4.51333333, ..., 0.01333333, 0.02666667,\n",
            "       0.        ])]\n"
          ]
        }
      ],
      "source": [
        "# get the adversarial exmaples\n",
        "interaction_array_manipulated = adversarial_manipulation(user_embeddings, item_embeddings, interaction_array, model1, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qiyxl5KH9GB"
      },
      "source": [
        "### Phase 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqe75o8BH9GB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b8efc1-6c90-49d5-8522-e2bacc7c68e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        user_idx  item_idx    rating\n",
            "0              0         0  4.000000\n",
            "1              0         1  4.000000\n",
            "2              0         2  4.000000\n",
            "3              0         3  5.000000\n",
            "4              0         4  5.000000\n",
            "...          ...       ...       ...\n",
            "149444       614      9718  0.031111\n",
            "149445       614      9719  0.035556\n",
            "149446       614      9720  0.013333\n",
            "149447       614      9721  0.013333\n",
            "149448       614      9722  0.026667\n",
            "\n",
            "[149449 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "user_indices, item_indices = np.nonzero(interaction_array_manipulated)  # Get indices of non-zero elements\n",
        "\n",
        "# Retrieve the corresponding ratings from interaction_array\n",
        "ratings = interaction_array_manipulated[user_indices, item_indices]\n",
        "\n",
        "# Create a DataFrame similar to the original ratings DataFrame\n",
        "reconstructed_ratings = pd.DataFrame({\n",
        "    'user_idx': user_indices,\n",
        "    'item_idx': item_indices,\n",
        "    'rating': ratings\n",
        "})\n",
        "\n",
        "# Print to verify\n",
        "print(reconstructed_ratings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = reconstructed_ratings"
      ],
      "metadata": {
        "id": "QR2WVV0UIMJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(ratings))\n",
        "val_size = int(0 * len(ratings))\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(ratings, [train_size, val_size])"
      ],
      "metadata": {
        "id": "kzmpqkefIlIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPMKB7x5H9GB"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(UserItemDataset(ratings.iloc[train_dataset.indices]), batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users = ratings['user_idx'].unique()\n",
        "items = ratings['item_idx'].unique()\n",
        "\n",
        "# Create mappings from user/item IDs to indices (used for embedding)\n",
        "user_to_idx = {user: idx for idx, user in enumerate(users)}\n",
        "item_to_idx = {item: idx for idx, item in enumerate(items)}\n",
        "\n",
        "# Convert user and item IDs in ratings to indices\n",
        "ratings['user_idx'] = ratings['user_idx'].apply(lambda x: user_to_idx[x])\n",
        "ratings['item_idx'] = ratings['item_idx'].apply(lambda x: item_to_idx[x])"
      ],
      "metadata": {
        "id": "vz2sM3cfJlgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = len(users)\n",
        "num_items = len(items)\n",
        "embedding_size = 50  # This is a tunable hyperparameter"
      ],
      "metadata": {
        "id": "-j2uuk0NIqW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mf_model2 = MFModel(num_users, num_items, embedding_size).to(device)\n",
        "optimizer = optim.Adam(mf_model2.parameters(), lr=0.001)  # Adam optimizer\n",
        "loss_fn = nn.MSELoss()  # Loss function (Mean Squared Error)"
      ],
      "metadata": {
        "id": "XnZveAmYJ89O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_users, num_items, mf_model2)"
      ],
      "metadata": {
        "id": "necKvJYEK6ka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d3a58d-d7ec-4247-f5d6-75f392276e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "615 9724 MFModel(\n",
            "  (user_embedding): Embedding(615, 50)\n",
            "  (item_embedding): Embedding(9724, 50)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mf_model(mf_model2, train_loader, optimizer, loss_fn)"
      ],
      "metadata": {
        "id": "4CjyVzxWLDNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e41251-c6d6-4b12-e078-62bae41891b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 43.5596\n",
            "Epoch 2/10, Loss: 24.4903\n",
            "Epoch 3/10, Loss: 16.6059\n",
            "Epoch 4/10, Loss: 11.5849\n",
            "Epoch 5/10, Loss: 7.5016\n",
            "Epoch 6/10, Loss: 4.4021\n",
            "Epoch 7/10, Loss: 2.6568\n",
            "Epoch 8/10, Loss: 1.7856\n",
            "Epoch 9/10, Loss: 1.3299\n",
            "Epoch 10/10, Loss: 1.0686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYIdLAdTLQby"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    user_embeddings = mf_model2.user_embedding.weight.cpu().numpy()\n",
        "    item_embeddings = mf_model2.item_embedding.weight.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgcSg49NLQby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267929b6-2c5f-4bb8-d497-2ac4f4cfe298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(615, 50)\n",
            "[[ 1.1934199  -0.18560572 -0.429208   ... -0.09170704  0.66021615\n",
            "  -0.70002294]\n",
            " [-0.7782157  -1.0830592   0.85988724 ...  1.0737648   1.0355741\n",
            "   1.6933202 ]\n",
            " [-1.3466654  -0.81042135  1.4166676  ... -0.4928114   0.8047629\n",
            "  -1.0115247 ]\n",
            " ...\n",
            " [ 0.35319883 -0.11706936 -0.14369167 ...  0.14567022 -0.06333251\n",
            "  -0.13987537]\n",
            " [ 0.18323533 -0.03571222 -0.10329661 ...  0.02786149  0.03955904\n",
            "  -0.1201558 ]\n",
            " [ 0.32783994 -0.07550949 -0.1614634  ...  0.15269202 -0.11671703\n",
            "  -0.14155258]]\n"
          ]
        }
      ],
      "source": [
        "print(user_embeddings.shape)\n",
        "print(user_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_graph_data = create_graph_data(ratings,num_users,user_embeddings,item_embeddings)"
      ],
      "metadata": {
        "id": "CxF_rMTXLucE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f814f1-5801-4a85-ea16-25dc971cf794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10339, 50])\n",
            "(2, 149449)\n",
            "[[    0     0     0 ...   614   614   614]\n",
            " [  615   616   617 ... 10335 10336 10337]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = GCNModel(in_channels=embedding_size, hidden_channels=64, out_channels=32).to(device)\n",
        "gcn_optimizer = optim.Adam(model2.parameters(), lr=0.01)\n",
        "gcn_loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "BgZaYzkIMPzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_matrix_manipulated = ratings.pivot(index='user_idx', columns='item_idx', values='rating').fillna(0)"
      ],
      "metadata": {
        "id": "zq6_6ExFYJCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_embeddings, item_embeddings= train_gcn_model(model2, train_graph_data, gcn_optimizer, gcn_loss_fn, interaction_matrix_manipulated)"
      ],
      "metadata": {
        "id": "198Y0mdTMju1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de27a578-60b4-44ae-f75a-70b8070a5354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 57.9441\n",
            "Epoch 2/30, Loss: 4.1436\n",
            "Epoch 3/30, Loss: 7.9179\n",
            "Epoch 4/30, Loss: 9.9670\n",
            "Epoch 5/30, Loss: 6.1768\n",
            "Epoch 6/30, Loss: 3.2390\n",
            "Epoch 7/30, Loss: 1.8769\n",
            "Epoch 8/30, Loss: 1.2812\n",
            "Epoch 9/30, Loss: 1.0234\n",
            "Epoch 10/30, Loss: 0.9083\n",
            "Epoch 11/30, Loss: 0.8528\n",
            "Epoch 12/30, Loss: 0.8171\n",
            "Epoch 13/30, Loss: 0.7840\n",
            "Epoch 14/30, Loss: 0.7502\n",
            "Epoch 15/30, Loss: 0.7147\n",
            "Epoch 16/30, Loss: 0.6781\n",
            "Epoch 17/30, Loss: 0.6404\n",
            "Epoch 18/30, Loss: 0.6031\n",
            "Epoch 19/30, Loss: 0.5675\n",
            "Epoch 20/30, Loss: 0.5342\n",
            "Epoch 21/30, Loss: 0.5035\n",
            "Epoch 22/30, Loss: 0.4758\n",
            "Epoch 23/30, Loss: 0.4512\n",
            "Epoch 24/30, Loss: 0.4294\n",
            "Epoch 25/30, Loss: 0.4103\n",
            "Epoch 26/30, Loss: 0.3935\n",
            "Epoch 27/30, Loss: 0.3788\n",
            "Epoch 28/30, Loss: 0.3659\n",
            "Epoch 29/30, Loss: 0.3547\n",
            "Epoch 30/30, Loss: 0.3449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_gcn_model(model2, user_embeddings, item_embeddings,  interaction_matrix_manipulated)"
      ],
      "metadata": {
        "id": "XzpUi0fXM3ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c6c0fb2-6e33-4438-ebc8-e2c94ef396d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.5872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the rmse for all 3 models calculated by predicting ratings for a new user"
      ],
      "metadata": {
        "id": "6LGW0cU4dudX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adversarial_interactions= interaction_array_manipulated[610:]\n",
        "# adversarial_interactions.shape"
      ],
      "metadata": {
        "id": "Q8h9-Died4bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing for RECsecure"
      ],
      "metadata": {
        "id": "dolBJnHAInQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_test(50, interaction_array_manipulated, item_embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgz9yFo72sOm",
        "outputId": "94c2bd54-eee7-459d-ce2f-6ee9c3832d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2668284680719553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adversarial_test = adversarial_interactions[np.random.choice(adversarial_interactions.shape[0])]\n",
        "# num_values_to_keep = 2000\n",
        "# non_zero_indices = np.nonzero(adversarial_test)[0]\n",
        "# selected_indices = np.random.choice(non_zero_indices, size=num_values_to_keep, replace=False)\n",
        "# masked_array = np.zeros_like(adversarial_test)\n",
        "# masked_array[selected_indices] = adversarial_test[selected_indices]\n",
        "# print(masked_array)"
      ],
      "metadata": {
        "id": "riLQDwgMHkBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction = predict_new_user_rating(item_embeddings, masked_array)"
      ],
      "metadata": {
        "id": "fIe8Tc-bI4-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rmse = np.sqrt(np.mean((prediction - adversarial_test) ** 2))\n",
        "# print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "id": "Ypi1NfkxXtOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing for RECmani"
      ],
      "metadata": {
        "id": "R_woB32vcnYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_test(50, interaction_array_manipulated, old_item_embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9_9yun-3GNu",
        "outputId": "98be69f6-6d44-4041-fb48-aec6a752fc72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2324665011308187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction = predict_new_user_rating(old_item_embeddings, masked_array)"
      ],
      "metadata": {
        "id": "aCBctVs1ctPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rmse = np.sqrt(np.mean((prediction - adversarial_test) ** 2))\n",
        "# print(\"RMSE:\", rmse)"
      ],
      "metadata": {
        "id": "gEZ3EL90czLg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}